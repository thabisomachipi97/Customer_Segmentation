{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQogc4aEMXDn"
   },
   "source": [
    "<h1 style=\"color:blue\" align=\"center\"><b> Market Segmentation in SBI life Insurance</b> </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOz0BCDq8AUA"
   },
   "source": [
    "# **1. Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oc83GFxrKoxg"
   },
   "source": [
    "### **Objective :**\n",
    "This case requires to develop a customer segmentation to give recommendations like saving plans, loans, wealth management, etc. on target customer groups. \n",
    "### **Data Description :**\n",
    "The sample Dataset summarizes the usage behavior of about 9000 active credit card holders during the last 6 months. The file is at a customer level with 18 behavioral variables.\n",
    "### **Data :**  \n",
    "Use the below link to download the Data Set:[here](https://www.kaggle.com/arjunbhasin2013/ccdata)\n",
    "\n",
    "### **Attribute Information :**\n",
    "Following is the Data Dictionary for customer's credit card dataset :-\n",
    "\n",
    "<b> CUSTID :</b> Identification of Credit Card holder (Categorical)<br>\n",
    "<b>BALANCE :</b> Balance amount left in their account to make purchases<br>\n",
    "<b>BALANCEFREQUENCY :</b> How frequently the Balance is updated, score between 0 and 1 (1 = frequently updated, 0 = not frequently updated)<br>\n",
    "<b>PURCHASES :</b> Amount of purchases made from account<br>\n",
    "<b>ONEOFFPURCHASES :</b> Maximum purchase amount done in one-go<br>\n",
    "<b>INSTALLMENTSPURCHASES :</b> Amount of purchase done in installment<br>\n",
    "<b>CASHADVANCE :</b> Cash in advance given by the user<br>\n",
    "<b>PURCHASESFREQUENCY :</b> How frequently the Purchases are being made, score between 0 and 1 (1 = frequently purchased, 0 = not frequently purchased)<br>\n",
    "<b>ONEOFFPURCHASESFREQUENCY :</b> How frequently Purchases are happening in one-go (1 = frequently purchased, 0 = not frequently purchased)<br>\n",
    "PURCHASESINSTALLMENTSFREQUENCY :</b> How frequently purchases in installments are being done (1 = frequently done, 0 = not frequently done)<br>\n",
    "<b>CASHADVANCEFREQUENCY :</b> How frequently the cash in advance being paid<br>\n",
    "<b>CASHADVANCETRX :</b> Number of Transactions made with \"Cash in Advanced\"<br>\n",
    "<b>PURCHASESTRX :</b> Numbe of purchase transactions made<br>\n",
    "<b>CREDITLIMIT :</b> Limit of Credit Card for user<br>\n",
    "<b>PAYMENTS :</b> Amount of Payment done by user<br>\n",
    "<b>MINIMUM_PAYMENTS :</b> Minimum amount of payments made by user<br>\n",
    "<b>PRCFULLPAYMENT :</b> Percent of full payment paid by user<br>\n",
    "<b>TENURE :</b> Tenure of credit card service for user<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FvURjqA38EFW"
   },
   "source": [
    "# **2. Import Libraries:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /snap/jupyter/6/lib/python3.7/site-packages (from pandas) (2.8.0)\n",
      "Collecting pytz>=2017.3 (from pandas)\n",
      "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/thabiso/snap/jupyter/common/lib/python3.7/site-packages (from pandas) (1.21.6)\n",
      "Requirement already satisfied: six>=1.5 in /snap/jupyter/6/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.12.0)\n",
      "Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━\u001b[0m \u001b[32m8.2/11.3 MB\u001b[0m \u001b[31m291.5 kB/s\u001b[0m eta \u001b[36m0:00:11\u001b[0m:10\u001b[0m"
     ]
    }
   ],
   "source": [
    "pip install pandas \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IV6dizi69rgG"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a9989d7135da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# import necessary libraries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans,AgglomerativeClustering,DBSCAN,SpectralClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIQCeJdP8QAg"
   },
   "source": [
    "# **3. Load Dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "A1aL8hILApBq",
    "outputId": "26f7675d-521f-42d5-ae6e-3948a5bab3c7"
   },
   "outputs": [],
   "source": [
    "# import the dataset\n",
    "creditcard_df = pd.read_csv(\"credit_card_dataset.csv\")\n",
    "creditcard_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t227bg8p8ZeK"
   },
   "source": [
    "# **4.Exploratory Data Analysis & Data Cleaning:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x642gG55IFH4",
    "outputId": "2aede765-c397-4443-b1be-7725f7527b79"
   },
   "outputs": [],
   "source": [
    "creditcard_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CPAXliTBApEZ",
    "outputId": "bc4536fa-1728-4c24-fda8-532d7f7799f1"
   },
   "outputs": [],
   "source": [
    "# information about the data\n",
    "creditcard_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the statistics summary of the dataframe\n",
    "creditcard_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9a6tZ053Do1L",
    "outputId": "11b76d55-158d-4ee7-e307-b21340c5485b"
   },
   "outputs": [],
   "source": [
    "# checking for Null values in data frame\n",
    "creditcard_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "168lrNY0L5m9",
    "outputId": "e750030f-88af-4b01-9fde-7d0a0998995e"
   },
   "outputs": [],
   "source": [
    "# find all columns having missing values\n",
    "missing_var = [var for var in creditcard_df.columns if creditcard_df[var].isnull().sum()>0]\n",
    "missing_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OItFRcH8L5yv"
   },
   "outputs": [],
   "source": [
    "# fill mean value in place of missing values\n",
    "creditcard_df[\"MINIMUM_PAYMENTS\"] = creditcard_df[\"MINIMUM_PAYMENTS\"].fillna(creditcard_df[\"MINIMUM_PAYMENTS\"].mean())\n",
    "creditcard_df[\"CREDIT_LIMIT\"] = creditcard_df[\"CREDIT_LIMIT\"].fillna(creditcard_df[\"CREDIT_LIMIT\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21VxCR_sL50m",
    "outputId": "0af46703-2316-4c82-de7c-5c021e51bdd9"
   },
   "outputs": [],
   "source": [
    "# Again check for null values\n",
    "creditcard_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nu1nwwsXL54g",
    "outputId": "7191f789-0699-4e98-8932-4018f4e0973d"
   },
   "outputs": [],
   "source": [
    "# check duplicate entries in the dataset\n",
    "creditcard_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P22UTnrlr-7D"
   },
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "creditcard_df.drop(columns=[\"CUST_ID\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zLzOtHtux2d0",
    "outputId": "6a48af58-d3b3-4e37-9bb5-c9fcc7645d89"
   },
   "outputs": [],
   "source": [
    "creditcard_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nscbI_ftEmSB"
   },
   "source": [
    "# **5. Outlier Detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bVKUswoJ8bnE",
    "outputId": "fa4452ec-80a6-4ba6-8198-6bebc8f6f3ec"
   },
   "outputs": [],
   "source": [
    "# find outlier in all columns\n",
    "for i in creditcard_df.select_dtypes(include=['float64','int64']).columns:\n",
    "  max_thresold = creditcard_df[i].quantile(0.95)\n",
    "  min_thresold = creditcard_df[i].quantile(0.05)\n",
    "  creditcard_df_no_outlier = creditcard_df[(creditcard_df[i] < max_thresold) & (creditcard_df[i] > min_thresold)].shape\n",
    "  print(\" outlier in \",i,\"is\" ,int(((creditcard_df.shape[0]-creditcard_df_no_outlier[0])/creditcard_df.shape[0])*100),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3d-9p2P5tYVR"
   },
   "outputs": [],
   "source": [
    "# remove outliers from columns having nearly 10% outlier\n",
    "max_thresold_BALANCE = creditcard_df[\"BALANCE\"].quantile(0.95)\n",
    "min_thresold_BALANCE = creditcard_df[\"BALANCE\"].quantile(0.05)\n",
    "max_thresold_CREDIT_LIMIT = creditcard_df[\"CREDIT_LIMIT\"].quantile(0.95)\n",
    "min_thresold_CREDIT_LIMIT = creditcard_df[\"CREDIT_LIMIT\"].quantile(0.05)\n",
    "max_thresold_PAYMENTS = creditcard_df[\"PAYMENTS\"].quantile(0.95)\n",
    "min_thresold_PAYMENTS = creditcard_df[\"PAYMENTS\"].quantile(0.05)\n",
    "creditcard_df_no_outlier = creditcard_df[(creditcard_df[\"CREDIT_LIMIT\"] < max_thresold_CREDIT_LIMIT) & (creditcard_df[\"CREDIT_LIMIT\"] > min_thresold_CREDIT_LIMIT) & (creditcard_df[\"BALANCE\"] < max_thresold_BALANCE) & (creditcard_df[\"BALANCE\"] > min_thresold_BALANCE) &  (creditcard_df[\"PAYMENTS\"] < max_thresold_PAYMENTS) & (creditcard_df[\"PAYMENTS\"] > min_thresold_PAYMENTS)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "8tVH1zV22z3T",
    "outputId": "862bc890-8094-4f18-f0a1-7ad6c66b356d"
   },
   "outputs": [],
   "source": [
    "# DataFrame having no outlier\n",
    "creditcard_df_no_outlier.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_df_no_outlier.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 738
    },
    "id": "hinJyKEnr_BS",
    "outputId": "ef4cc0e9-7df0-4421-ac60-ce170408a504"
   },
   "outputs": [],
   "source": [
    "# correlation matrix of DataFrame\n",
    "plt.figure(figsize=(20,10))\n",
    "corn=creditcard_df_no_outlier.corr()\n",
    "sns.heatmap(corn,annot=True,cmap=\"BuPu\",fmt='.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the results, we can see 3 pairs of strong correlation\n",
    "1. \"PURCHASES\" and \"ONEOFF_PURCHASES\" -- 0.86\n",
    "2. \"PURCHASES_FREQUENCY\" and 'PURCHASES_INSTALLMENT_FREQUENCY' --0.85\n",
    "3. \"CASH_ADVANCE_TRX\" and \"CASH_ADVANCE_FREQUENCY\" --0.81"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **6. Scaling the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to scale our values to give them all equal importance. Scaling is also important from a clustering perspective as the distance between points affects the way clusters are formed.\n",
    "\n",
    "Using the StandardScaler, we transform our dataframe into the following numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_Jyux8tr_Ds"
   },
   "outputs": [],
   "source": [
    "# scale the DataFrame\n",
    "scalar=StandardScaler()\n",
    "creditcard_scaled_df = scalar.fit_transform(creditcard_df_no_outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "creditcard_scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xGnQd2sZLFXL"
   },
   "source": [
    "# **7. Dimensionality reduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> Dimensionality reduction is a technique used to reduce the number of features in a dataset while retaining as much of the important information as possible. \n",
    "\n",
    "-> In other words, it is a process of transforming high-dimensional data into a lower-dimensional space that still preserves the essence of the original data.\n",
    "\n",
    "-> This can be done for a variety of reasons, such as to reduce the complexity of a model, to reduce the storage space, to improve the performance of a learning algorithm, or to make it easier to visualize the data. \n",
    "\n",
    "-> There are several techniques for dimensionality reduction, \n",
    "* including principal component analysis (PCA), \n",
    "* singular value decomposition (SVD), \n",
    "* and linear discriminant analysis (LDA). \n",
    "\n",
    "Each technique uses a different method to project the data onto a lower-dimensional space while preserving important information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "M6GMphxjqWGJ",
    "outputId": "075c34d0-cb62-4ced-9643-10f03a9c51e0"
   },
   "outputs": [],
   "source": [
    "# convert the DataFrame into 2D DataFrame for visualization\n",
    "pca = PCA(n_components=2)\n",
    "principal_comp = pca.fit_transform(creditcard_scaled_df)\n",
    "pca_df = pd.DataFrame(data=principal_comp,columns=[\"pca1\",\"pca2\"])\n",
    "pca_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQF4hlEsuprz"
   },
   "source": [
    "# **8. Hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "id": "MtmR-6zBr_Il",
    "outputId": "632d60e0-b461-4d03-87d5-5547498969db"
   },
   "outputs": [],
   "source": [
    "# find 'k' value by Elbow Method\n",
    "inertia = []\n",
    "range_val = range(1,15)\n",
    "for i in range_val:\n",
    "  kmean = KMeans(n_clusters=i)\n",
    "  kmean.fit_predict(pd.DataFrame(creditcard_scaled_df))\n",
    "  inertia.append(kmean.inertia_)\n",
    "plt.plot(range_val,inertia,'bx-')\n",
    "plt.xlabel('Values of K') \n",
    "plt.ylabel('Inertia') \n",
    "plt.title('The Elbow Method using Inertia') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this plot, 4th cluster seems to be the elbow of the curve.\n",
    "However, the values does not reduce to linearly until 8th cluster, so we may consider using 8 clusters in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h75MkXAwI7zg"
   },
   "source": [
    "# **9. Model Building**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exJLE2rTtxIe"
   },
   "source": [
    "## ** K-Means Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply kmeans algorithm\n",
    "kmeans_model=KMeans(4)\n",
    "kmeans_model.fit_predict(creditcard_scaled_df)\n",
    "pca_df_kmeans= pd.concat([pca_df,pd.DataFrame({'cluster':kmeans_model.labels_})],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 518
    },
    "id": "l2Txeh9g3EAG",
    "outputId": "344a6623-c01f-4870-f026-1e1c7826292c"
   },
   "outputs": [],
   "source": [
    "# visualize the clustered dataframe\n",
    "# Scatter Plot\n",
    "plt.figure(figsize=(8,8))\n",
    "#palette=['dodgerblue','red','green','blue','black','pink','gray','purple','coolwarm']\n",
    "ax=sns.scatterplot(x=\"pca1\",y=\"pca2\",hue=\"cluster\",data=pca_df_kmeans,palette=['red','green','blue','black'])\n",
    "plt.title(\"Clustering using K-Means Algorithm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OH_HCsgJgwXs"
   },
   "source": [
    "## **9.1. Analyzing Clustering Output**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxv4lEA7O4Hq"
   },
   "source": [
    "We've used K-Means model for clustering in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_model.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JPnCI9agqV5y"
   },
   "outputs": [],
   "source": [
    "# find all cluster centers\n",
    "cluster_centers = pd.DataFrame(data=kmeans_model.cluster_centers_,columns=[creditcard_df.columns])\n",
    "# inverse transfor the data\n",
    "cluster_centers = scalar.inverse_transform(cluster_centers)\n",
    "cluster_centers = pd.DataFrame(data=cluster_centers,columns=[creditcard_df.columns])\n",
    "cluster_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lWLN4UnpqWB_"
   },
   "outputs": [],
   "source": [
    "# create a column as \"cluster\" & store the respective cluster name that they belongs to\n",
    "creditcard_cluster_df = pd.concat([creditcard_df,pd.DataFrame({'cluster':kmeans_model.labels_})],axis=1)\n",
    "creditcard_cluster_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **9.2 Outcome**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> There are 4 clusters (segments)- each clusters are shown below in detail:\n",
    "* First Customers cluster (Transactors): Those are customers who pay least amount of interest charges and careful with their money, Cluster with lowest balance (104 Dollar) and cash advance (303 Dollar), Percentage of full payment = 23%\n",
    "\n",
    "* Second customers cluster (revolvers) who use credit card as a loan (most lucrative sector): highest balance (5000 Dollar) and cash advance (5000 Dollar), low purchase frequency, high cash advance frequency (0.5), high cash advance transactions (16) and low percentage of full payment (3%)\n",
    "\n",
    "* Third customer cluster (VIP/Prime): high credit limit 16K Dollar and highest percentage of full payment, target for increase credit limit and increase spending habits\n",
    "\n",
    "* Fourth customer cluster (low tenure): these are customers with low tenure (7 years), low balance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H6dmahpojNBK"
   },
   "source": [
    "## **9.3. Analysis of each Cluster**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0ucdv9KjgTv"
   },
   "source": [
    "### Cluster - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "OgxDkByUhEZE",
    "outputId": "ac4aea4a-c0a5-4eb8-8a4c-90599af1c4cd"
   },
   "outputs": [],
   "source": [
    "cluster_1_df = creditcard_cluster_df[creditcard_cluster_df[\"cluster\"]==0]\n",
    "cluster_1_df.sort_values(by=['BALANCE'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8i0L9Sgk_JG"
   },
   "source": [
    "### Cluster - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "g8gZ0SU1jRrf",
    "outputId": "927e77f9-3f35-4dfa-a3b1-fae9a1dbb3c4"
   },
   "outputs": [],
   "source": [
    "cluster_2_df = creditcard_cluster_df[creditcard_cluster_df[\"cluster\"]==1]\n",
    "cluster_2_df.sort_values(by=['BALANCE'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gIVDZ3RXlBX0"
   },
   "source": [
    "### Cluster - 3 (Silver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "d1FAq1DnjR3E",
    "outputId": "1071f179-fc74-47a5-ccfe-6d370019ed0d"
   },
   "outputs": [],
   "source": [
    "cluster_3_df = creditcard_cluster_df[creditcard_cluster_df[\"cluster\"]==2]\n",
    "cluster_3_df.sort_values(by=['BALANCE'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xm0N4gn9lDu_"
   },
   "source": [
    "### Cluster - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "5hOABUdHkXoU",
    "outputId": "430fdb09-d5b8-4e53-c706-e57826506c0e"
   },
   "outputs": [],
   "source": [
    "cluster_4_df = creditcard_cluster_df[creditcard_cluster_df[\"cluster\"] == 3]\n",
    "cluster_4_df.sort_values(by=['BALANCE'], ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edCwjspqOCD5"
   },
   "source": [
    "# **10. Save The Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2jmKZxzqOI0D",
    "outputId": "12b0c435-42df-47fd-cdd7-8501fa6d6aeb"
   },
   "outputs": [],
   "source": [
    "#Saving Scikitlearn models\n",
    "import joblib\n",
    "joblib.dump(kmeans_model, \"kmeans_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OefYGmi5P2xu"
   },
   "outputs": [],
   "source": [
    "# save the dataframe in .csv file named as \"Clustered_Costumer_Data\"\n",
    "creditcard_cluster_df.to_csv(\"Clustered_Customer_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Market_Segmentation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
